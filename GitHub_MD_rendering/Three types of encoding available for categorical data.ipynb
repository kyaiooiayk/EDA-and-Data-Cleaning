{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**What?** Three types of encoding available for categorical data\n",
    "\n",
""   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal Encoding\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- By default, it will assign integers to labels in the order that is observed in the data. If a specific order is desired, it can be specified via the `categories` argument as a list with the rank order of all expected labels.\n",
    "- For strings, this means the labels are sorted alphabetically, and to be honest this **may cause some confusion**.\n",
    "- In my opinion ordinal shouls imply an order by defaul.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['red']\n",
      " ['green']\n",
      " ['blue']]\n",
      "[[2.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# define data\n",
    "data = asarray([['red'], ['green'], ['blue']])\n",
    "print(data)\n",
    "# define ordinal encoding\n",
    "encoder = OrdinalEncoder()\n",
    "# transform data\n",
    "result = encoder.fit_transform(data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['blue']\n",
      " ['green']\n",
      " ['red']]\n",
      "[[0.]\n",
      " [1.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "# define data\n",
    "data = asarray([['blue'], ['green'], ['red']])\n",
    "print(data)\n",
    "# define ordinal encoding\n",
    "encoder = OrdinalEncoder()\n",
    "# transform data\n",
    "result = encoder.fit_transform(data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Let us assume I have three categories \"low\", \"medium\", \"high\" and I'd like to keepp this order.\n",
    "- If I feed this info to the encoder I will get low=1, medium=2 and high=0 which is not what I want.\n",
    "- I'd like to keep the order, meaning \"low\" is less important than \"high\", to do this, I will have to use the `categories` argument. \n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['low']\n",
      " ['medium']\n",
      " ['high']]\n",
      "[[1.]\n",
      " [2.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# define data\n",
    "data = asarray([['low'], ['medium'], ['high']])\n",
    "print(data)\n",
    "# define ordinal encoding\n",
    "encoder = OrdinalEncoder()\n",
    "# transform data\n",
    "result = encoder.fit_transform(data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['low']\n",
      " ['medium']\n",
      " ['high']]\n",
      "[[0.]\n",
      " [1.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "# define data\n",
    "data = asarray([['low'], ['medium'], ['high']])\n",
    "print(data)\n",
    "# define ordinal encoding with an order NOW specified!\n",
    "encoder = OrdinalEncoder(\n",
    "    categories=[['low', 'medium', 'high']])\n",
    "# transform data\n",
    "result = encoder.fit_transform(data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- We can demonstrate the usage of the OneHotEncoder on the color categories.\n",
    "- First the categories are sorted, in this case alphabetically because they are strings, then binary variables are created for each category in turn.\n",
    "- This means blue will be represented as [1, 0, 0] with a 1 in for the first binary variable, then green, then finally red.\n",
    "- The one-hot encoding **creates one binary variable for each category**.\n",
    "\n",
    "</font >\n",
    "</div >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['red']\n",
      " ['green']\n",
      " ['blue']]\n",
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# define data\n",
    "data = asarray([['red'], ['green'], ['blue']])\n",
    "print(data)\n",
    "# define one hot encoding\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "# transform data\n",
    "onehot = encoder.fit_transform(data)\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['red']\n",
      " ['green']\n",
      " ['blue']\n",
      " ['balck']]\n",
      "[[0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# define data\n",
    "data = asarray([['red'], ['green'], \n",
    "                ['blue'], [\"balck\"]])\n",
    "print(data)\n",
    "# define one hot encoding\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "# transform data\n",
    "onehot = encoder.fit_transform(data)\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Variable Encoding\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The one hot encoding creates one binary variable for each category. \n",
    "- The problem is that this representation includes redundancy. \n",
    "- For example, if we know that [1, 0, 0] represents blue and [0, 1, 0] represents green we don’t need another binary variable to represent red, instead we could use 0 values alone, e.g. [0, 0]. \n",
    "- This is called a dummy variable encoding, and always represents C categories with C − 1 binary variables.\n",
    "- The `drop` argument can be set to indicate which category will be come the one that is assigned all zero values, called the “baseline“. We can set this to “first” so that the first category is used. When the labels are sorted alphabetically, the first “blue” label will be the first and will become the baseline.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['red']\n",
      " ['green']\n",
      " ['blue']]\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# define data\n",
    "data = asarray([['red'], ['green'], ['blue']])\n",
    "print(data)\n",
    "# define one hot encoding\n",
    "encoder = OneHotEncoder(drop='first',\n",
    "                        sparse=False)\n",
    "# transform data\n",
    "onehot = encoder.fit_transform(data)\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['red']\n",
      " ['green']\n",
      " ['blue']\n",
      " ['black']]\n",
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# define data\n",
    "data = asarray([['red'], ['green'], \n",
    "                ['blue'], [\"black\"]])\n",
    "print(data)\n",
    "# define one hot encoding\n",
    "encoder = OneHotEncoder(drop='first',\n",
    "                        sparse=False)\n",
    "# transform data\n",
    "onehot = encoder.fit_transform(data)\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAQs\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **What if I have hundreds of categories?** Or, what if I concatenate many one hot encoded vectors to create a many thousand element input vector? You can use a one hot encoding up to thousands and tens of thousands of categories. Also, having large vectors as input sounds intimidating, but the models can generally handle it. Try an embedding; it offers the benefit of a smaller vector space (a projection) and the representation can have more meaning.\n",
    "\n",
    "- **What encoding technique is the best?** This is unknowable as it will probably depends on both the dataset and the algorithm used. Test each technique (and more) on your dataset with your chosen model and discover what works best for your case.\n",
    "\n",
    "- **What is you really want to avoid?** Do not mislead the model! For categorical variables where no ordinal relationship exists, the integer encoding may not be enough, at best, or misleading to the model at worst. In fact if we assign integer number, the model may have a tendency to rank its entries from the smallest to the highest which something we do not really want to do. Forcing an ordinal relationship via an ordinal encoding and allowing the model to assume a natural ordering between categories may result in poor performance or unexpected results (*predictions halfway between categories*).\n",
    "\n",
    "- **Is there any case where you'll be wrong to use one method instead of the other?** Yes, there is one case. For example, in the case of a linear regression model (and other regression models that have a bias term), a one hot encoding will case the matrix of input data to become singular, meaning it cannot be inverted and the linear regression coefficients cannot be calculated using linear algebra. For these types of models a dummy variable encoding must be used instead.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example on a real dataset\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The example below is just an example, that sometimes you have to try both methods and see if there are any notable differences youself.\n",
    "- This is the case shown below.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OrdinalEncoder Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.79\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "dataset = read_csv('../DATASETS/breast-cancer.csv', header=None)\n",
    "# retrieve the array of data\n",
    "data = dataset.values\n",
    "# separate into input and output columns\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "# split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1) \n",
    "# ordinal encode input variables\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "ordinal_encoder.fit(X_train)\n",
    "X_train = ordinal_encoder.transform(X_train)\n",
    "X_test = ordinal_encoder.transform(X_test)\n",
    "# ordinal encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# fit on the training set\n",
    "model.fit(X_train, y_train)\n",
    "# predict on test set\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat) \n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneHotEncoder Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.53\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "dataset = read_csv('../DATASETS/breast-cancer.csv', header=None)\n",
    "# retrieve the array of data\n",
    "data = dataset.values\n",
    "# separate into input and output columns\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "# split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1) \n",
    "# one-hot encode input variables\n",
    "onehot_encoder = OneHotEncoder()\n",
    "onehot_encoder.fit(X_train)\n",
    "X_train = onehot_encoder.transform(X_train)\n",
    "X_test = onehot_encoder.transform(X_test)\n",
    "# ordinal encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# fit on the training set\n",
    "model.fit(X_train, y_train)\n",
    "# predict on test set\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- https://machinelearningmastery.com/how-to-prepare-categorical-data-for-deep-learning-in-python/\n",
    "- https://datascience.stackexchange.com/questions/39317/difference-between-ordinalencoder-and-labelencoder/64177\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
